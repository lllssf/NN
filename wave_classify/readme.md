# 说明文档
<!-- TOC -->

- [1. 任务一：小样本信号分类](#1-任务一小样本信号分类)
    - [1.1 数据处理](#11-数据处理)
    - [1.2 分类](#12-分类)
- [2. 任务二：扩大样本的信号分类](#2-任务二扩大样本的信号分类)
    - [2.1 数据处理](#21-数据处理)
    - [2.2 分类](#22-分类)
- [3. 任务三：对既定位置的信号识别](#3-任务三对既定位置的信号识别)
    - [3.1 数据处理](#31-数据处理)
        - [3.1.1 原始数据解释](#311-原始数据解释)
        - [3.1.2 找出各位置光纤的数据分布](#312-找出各位置光纤的数据分布)
        - [3.1.3 制作数据集](#313-制作数据集)
    - [3.2 分类](#32-分类)
        - [基于联合采集数据集](#基于联合采集数据集)
        - [基于混合数据集](#基于混合数据集)
        - [基于剔除无效信号的混合数据集](#基于剔除无效信号的混合数据集)
- [模型的使用](#模型的使用)

<!-- /TOC -->
# 1. 任务一：小样本信号分类

## 1.1 数据处理

数据处理的python文件为：[wave_dataset_1.ipynb](\smallestData\wave_dataset_1.ipynb), 内含详细注释与运行结果。以下做简要梳理。

原始数据文件为：
- 脚踏：
  - [foot-data-2019-12-04-08-53-22.txt](\smallestData\foot-data-2019-12-04-08-53-22.txt)
  - [foot-data-2019-12-04-09-17-32.txt](\smallestData\foot-data-2019-12-04-09-17-32.txt)
- 手触：
  - [hand-data-2019-12-04-09-11-55.txt](\smallestData\hand-data-2019-12-04-09-11-55.txt)
  - [hand-data-2019-12-04-09-19-55.txt](\smallestData\hand-data-2019-12-04-09-19-55.txt)
- 棒击：
  - [stick-data-2019-12-04-09-04-41.txt](\smallestData\stick-data-2019-12-04-09-04-41.txt)
  - [stick-data-2019-12-04-09-18-45.txt](\smallestData\stick-data-2019-12-04-09-18-45.txt)
- 正常信号：
  - [normal-data-2019-12-04-09-06-26.txt](\smallestData\normal-data-2019-12-04-09-06-26.txt)
  - [normal-data-2019-12-04-09-21-09.txt](\smallestData\normal-data-2019-12-04-09-21-09.txt)

每个文件包含250组数据，每组数据3900个点。然后对所有文件使用相差法处理数据，并去除每组数据的前150个点。处理后各类型信号包含499组数据，每组3750个点。

依据10：1：1划分数据集的原则，将所有数据划分为1668条训练数据，164条验证数据，164条测试数据，每条数据的size为`(1，3750)`

## 1.2 分类

训练模型与测试的python文件为：[wave_classify_1.ipynb](\smallestData\wave_classify_1.ipynb), 模型选择为一维CNN，层数与残差模块个数为可调超参。整个网络超参有：

- batch_size 根据硬件条件与需要的运算速度选择。
- epochs 开始可设大一些，然后根据结果选择early stopping达到最好效果。
- num_blocks 残差模块个数
- filters 卷积核个数
- drop_rate Dropout的概率，根据过拟合程度调整
- num_class: 分类类别数目

结果：

- 训练集loss为0.030056355933014017，准确率为0.9975961446762085
- 验证集loss为0.06564075164496899，准确率为0.9937499761581421
- 测试集loss为0.03438437507465118，准确率为0.9939024448394775

# 2. 任务二：扩大样本的信号分类

## 2.1 数据处理

数据处理的python文件为：[wave_dataset_2.ipynb](\AugData\wave_dataset_2.ipynb), 内含详细注释与运行结果。

原始数据在`data2000`文件夹内，包含3类信号共24个文件，每类信号共2000组数据，每组3900个点，经过处理后，每类信号共1999组数据，每组数据有3750个点。划分数据集后得到4995条训练数据，501条验证数据，501条测试数据。其中每条数据的size为`(1，3750)`

## 2.2 分类

训练模型与测试的python文件为：[wave_classify_2.ipynb](\AugData\wave_classify_2.ipynb), 模型结构不变，对超参合理调整，得到的结果为：

- 训练集loss为0.006494189302126567，准确率为0.9989984035491943
- 验证集loss为0.08075833001307078，准确率为0.9754464030265808
- 测试集loss为0.08794098829259415，准确率为0.9640718698501587

# 3. 任务三：对既定位置的信号识别

## 3.1 数据处理

数据处理的python文件为：[wave_dataset_3.ipynb](\MultiData\wave_dataset_3.ipynb), 内含详细注释与运行结果。

### 3.1.1 原始数据解释

原始数据分为两大类：对单个光纤产生扰动的信号与对三个位置的光纤同时进行三种扰动的信号，其中，我把前者在注释中称为“单次采集”，把后者称为“联合采集”。在联合采集中，脚踏第一个位置的光纤，手触第二个位置的光纤，棒击第三个位置的光纤。

- 单次采集的文件包括：
  - 对第一个位置的光纤进行扰动的三个文件：
    - foot_pre.txt共有10000000个点，一共2000组，每组5000个点
    - hand_pre.txt共有10000000个点，一共2000组，每组5000个点
    - stick_pre.txt共有10000000个点，一共2000组，每组5000个点
  - 对第二个位置的光纤进行扰动的三个文件：
    - foot_middle.txt共有10000000个点，一共2000组，每组5000个点
    - hand_middle.txt共有10000000个点，一共2000组，每组5000个点
    - stick_middle.txt共有10000000个点，一共2000组，每组5000个点
  - 对第三个位置的光纤进行扰动的三个文件：
    - foot_last.txt共有10000000个点，一共2000组，每组5000个点
    - hand_last.txt共有10000000个点，一共2000组，每组5000个点
    - stick_last.txt共有10000000个点，一共2000组，每组5000个点
- 联合采集的文件为：three.txt共有10000000个点，一共2000组，每组5000个点

### 3.1.2 找出各位置光纤的数据分布

首先对单次采集得到的各个文件的数据进行处理，通过图像对比明确三个位置光纤在5000个数据点上的数据分布情况。通过[wave_dataset_3.ipynb](\MultiData\wave_dataset_3.ipynb)中的运行结果的图像可以看出，三个光纤的信号集中在`[2250:2400]`这150个点内。为了方便之后的网络训练，所以要将其切分为同一维度的数据，最后选择第一个位置的光纤信号范围为`[2250:2300]`，第二个为`[2300:2350]`，第三个为`[2350:2400]`。然后以此为依据对联合采集的信号进行处理。

根据后续任务的不同需求，可以划分别的长度。

### 3.1.3 制作数据集

虽然理论上知道50个点所包含的信息太少，不利于进行机器学习任务，但为了验证依旧划分了一维数据集与二维数据集。一维数据的size为`(1,50)`，二维数据的size为`(50,50)`，其中关于二维数据的维度选择没有标准，可根据计算速度及识别精度需求合理选择。详细的处理过程见代码及注释，以下解释一下划分结果：

- `three`文件夹包含对联合采集数据处理得到的一维信号：有4995条训练数据，501条验证数据，501条测试数据
- `three2D`文件夹包含对联合采集数据处理得到的二维信号：4869条训练数据，489条验证数据，489条测试数据
- `mix`文件夹包含对所有数据处理得到的一维信号：19992条训练数据，1998条验证数据，1998条测试数据
- `mix2D`文件夹包含对所有数据处理得到的二维信号：19866条训练数据，1986条验证数据，1986条测试数据
- `valid`文件夹是将`mix`内峰值2000以下的“无效”数据剔除后得到的一维数据：7329条训练数据，732条验证数据，732条测试数据
- `valid2D`文件夹是将`mix2D`内峰值2000以下的“无效”数据剔除后得到的二维数据：12198条训练数据，1219条验证数据，1219条测试数据

## 3.2 分类

训练模型与测试的python文件为：[wave_classify_2.ipynb](\MultiData\wave_classify_3.ipynb), 为了保证对一维二维数据的兼容，仍未改变模型结构，只是为了更优的效果对超参合理调整，得到的结果为：
### 基于联合采集数据集
1. 一维信号分类结果
   - 4995条训练数据，501条验证数据，501条测试数据
   - 训练集准确率为94.5%, 测试集准确率为90.6%

2. 二维信号分类结果
   - 4869条训练数据，489条验证数据，489条测试数据 
   - 训练集准确率为100%, 测试集准确率为100%

### 基于混合数据集
1. 一维混合信号分类结果
   - 19992条训练数据，1998条验证数据，1998条测试数据
   - 训练集准确率为76.8%, 测试集准确率为70.7%
2. 二维混合信号分类结果
   - 19866条训练数据，1986条验证数据，1986条测试数据
   - 训练集准确率为100%, 测试集准确率为100%

### 基于剔除无效信号的混合数据集
1. 一维有效信号分类结果
   - 7329条训练数据，732条验证数据，732条测试数据
   - 训练集准确率为91.2%, 测试集准确率为72.4%
2. 二维有效信号分类结果
   - 12198条训练数据，1219条验证数据，1219条测试数据
   - 训练集准确率为99.9%, 测试集准确率为100%

# 模型的使用

1. 模型训练好后，达到了理想效果就及时保存。而因为模型是使用python版本的Keras框架搭建的，其模型保存为`h5`格式，如在有Keras框架的python程序中可以直接load使用。
2. 要将`h5`使用[h52pb.py](./h52pb.py)模型转存为tensorflow可以调用的`pb`模型，其中需要注意的是，在哪台机器上训练的模型就必须用同一台机器进行模型转换。
3. C++使用pb模型，可以参考[C++调用pb文件](https://blog.csdn.net/wiscol/article/details/96492296)
